---
title: "Determinants of ecstasy use and harm reduction practices"
author: "Gjalt-Jorn Peters & Marion Oomens"
date: "`r format(Sys.time(), '%H:%M:%S on %Y-%m-%d %Z (GMT%z)')`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
########################################################################
### Load packages
########################################################################

require('userfriendlyscience');  ### For convenience functions, e.g. 'safeRequire'
safeRequire('here');             ### To easily access files using 'relative paths'
safeRequire('plyr');             ### For easily processing and restructuring data
safeRequire('dplyr');            ### Also for easily processing and restructuring data
safeRequire('purrr');            ### Iteration and the %||% operator
safeRequire('lubridate');        ### For working with dates
safeRequire("googlesheets");     ### To import data from google sheets in metabefor
safeRequire('jsonlite');         ### To import a list of country codes in metabefor
safeRequire('knitr');            ### For kable
safeRequire('data.tree');        ### To work with data structured in a tree in metabefor
safeRequire('devtools');         ### To install metabefor from github repo
                                 ### ... Which we then do here:
devtools::install_github("Matherion/metabefor");
require('metabefor');

########################################################################
### Settings
########################################################################

### By default hide R code
knitr::opts_chunk$set(echo = FALSE);
knitr::opts_chunk$set(comment = NA);

### Set path for query hit exports
queryHitExportPath <- here::here("queries");

### Set path for screening
screeningPath <- here::here("screening");

### Set path for extraction script template
extractionScriptTemplatePath <- here::here("extraction");

### Create object to keep track of queries
queries <- list();

### Simple function to correctly capture figures
figCap <- function(caption) {
  figCapCounter <-
    ifelse(is.null(getOption('figCapCounter')),
           0,
           getOption('figCapCounter'));
  figCapCounter <- figCapCounter + 1;
  options(figCapCounter = figCapCounter);
  return(paste0("Figure ", figCapCounter, ": ", caption));
}

### Set figure counter to 0
options(figCapCounter = 0);

```

```{r first-query-setup}
queries[[length(queries) + 1]] <-
  list(date = ymd("2018-07-01"),
       query = query_requiredConcepts(conceptName="Determinants of\necstasy use\nand harm reducation strategies",
                                      query_conceptTerms(conceptName = "Ecstasy",
                                                         "clubdrug*",
                                                         "club near drug*",
                                                         "dance near drug*",
                                                         "dancedrug*",
                                                         "party near drug*",
                                                         "partydrug*",
                                                         "xtc",
                                                         "mdma",
                                                         "methylenedioxymethamphetamine",
                                                         "3,4-methylenedioxymethamphetamine",
                                                         "ecstasy"),
                                      query_conceptTerms(conceptName = "Theory",
                                                         "(theor*) or (attitud*) or (motivat* near functio*) or (mode*) or (norm*) or
(perceived near control) or (pbc) or (’social cognitive’) or (self adj efficacy)
or (stages near change) or (perceived adj (harm or risk or functions)) or
(functional) or (outcome adj (expectancies or expectations)) or (sct) or (tpb)
or (patter*) or (psychosoc*) or (health adj belief adj model) or (hbm)"),
                                      query_conceptTerms(conceptName = "Determinants",
                                                         "(determin*) or (facto*) or (variabl*) or (parameter*) or (reason*) or (caus*) or
(motiv*) or (incentive*) or (correlat*) or (antecedent*) or (character*)"),
                                      query_conceptTerms(conceptName = "Initiation",
                                                         "(start*) or (commenc*) or (originat*) or (onset) or (initiat*) or (instigat*) or
((use) not (user)) or (using) or (usage) or (establish*)"),
                                      query_conceptTerms(conceptName = "Maintenacce",
                                                         "(maint*) or (sustain*) or (continu*) or (uphold*) or (persist*) or (further*) or
(prolong*)"),
                                      query_conceptTerms(conceptName = "Cessation",
                                                         "(end*) or (stop*) or (discontinu*) or (terminat*) or (ceas*) or (cessat*) or
(abstain*) or (abstin*) or (quit*) or (remiss*) or (resolut*) or (recover*)"),
                                      query_conceptTerms(conceptName = "Harm Reduction",
                                                         "(harm or risk or damage or casualt*) and (reduc* or manag* or limit* or
minimi*)"),
                                      query_conceptTerms(conceptName = "Excluded",
                                                         "((treatment not (‘not in treatment’ or ‘non-treatment’ or ‘non- treatment’ or
‘no treatment’)) or rat or rats or mouse or mice or animal or monkey* or
pigeon* or spectro* or cardio* or seroton* or dopamin* or neurotransm* or
receptor* or psychiatr* or psychopath* or cell* or diagnos*)")),
       databases = c(psycinfo = "RIS",
                     pubmed = "RIS"),
       fields = "title");
```

## First query, executed at: `r queries[[1]]$date;`

The first query is:

```{r query1-visual, screenshot.force=FALSE}
SetGraphStyle(queries[[1]]$query, rankdir = "LR")
plot(queries[[1]]$query);
```

In this plot, the 'AND' operator is visualised by a solid line, while the 'OR' operator is visualised by a dotted line.

<!-- In this query, the searched terms must occur in entries' `r queries[[1]]$fields` fields. -->

<!-- In the interface language of the PubMed interface to the PubMed database and the Ebscohost and Ovid interfaces to a variety of databases such as PsycINFO, PsycArticles, and MedLine, this query renders as: -->

```{r}
# query_toInterfaceLang(queries[[1]]$query,
#                       fields=queries[[1]]$fields);
```

<!-- This query was run at `r queries[[1]]$date;` in PubMed (XXXX hits; file saved as <code>pubmed-`r queries[[1]]$date`.ris</code>) and PsycINFO accessed through EbscoHost (XXXX hits; file saved as <code>psycinfo-`r queries[[1]]$date`.ris</code>), and exported to RIS format (called 'medline' in PubMed). The RIS files were then imported in R using `metabefor`. -->

```{r echo=TRUE, eval=FALSE}

# ### Import PsycINFO hits
# firstQueryIteration_psycinfo <-
#   importRISlike(file.path(queryHitExportPath,
#                           paste0("psycinfo-", queries[[1]]$date, ".ris"),
#                 encoding="native.enc");
# 
# ### Import PubMed hits
# firstQueryIteration_pubmed <-
#   importRISlike(file.path(queryHitExportPath,
#                           paste0("pubmed-", queries[[1]]$date, ".ris")));
# 
# ### Merge the two sets of hits
# firstQueryIteration <-
#   findDuplicateReferences(primaryRefs = firstQueryIteration_psycinfo,
#                           secondaryRefs = firstQueryIteration_pubmed,
#                           duplicateFieldValue = "dupl",
#                           newRecordValue = "PubMed",
#                           duplicateValue = "duplicate (both PsycINFO and PubMed)",
#                           originalValue = "PsycINFO");
# 
# ### Generate bibtex keys
# firstQueryIteration$output$records <-
#   generateBibtexkeys(firstQueryIteration$output$records);
# 
# ### Add query date identifier to bibtex keys
# firstQueryIteration$output$records$bibtexkey <-
#   paste0(firstQueryIteration$output$records$bibtexkey,
#          "-", gsub("-", "", queries[[1]]$date));
# 
# ### Export the hits to bibtex for screening in JabRef
# sysrevExport(firstQueryIteration,
#              filename=file.path(screeningPath,
#                                 paste0(queries[[1]]$date, "-screening.bib")),
#              screeningType="screening");

```

<!-- The merged list of query hits has now been exported to file <code>`r queries[[1]]$date`-screening.bib</code> in directory "screening" and can be opened using JabRef, which can be downloaded from https://www.fosshub.com/JabRef.html. -->

<!-- ## JabRef configuration -->

<!-- When opening a bibliographic library (i.e. a file with the extension `.bib`) in JabRef, it will show the entry table, which is a convenient way to inspect all entries (hits, references, articles, etc) in the library. To prepare JabRef for screening, two settings are important. -->

<!-- First, to change the fields that are visible in the overview table of all references (i.e. the entry table), open the 'Options' drop-down menu and select 'Preferences'. In the preferences dialog, open the 'Entry table columns' section: -->

<!-- ![Figure 1: Screenshot of JabRef preferences dialog when the 'Entry table columns' section is opened.](../img/jabref--preferences--entry-table-columns.png) -->

<!-- There, the columns shown in the entry table can be edited in the 'Entry table columns' sections. A bit confusingly, this is done by adding *rows* in the table shown in this dialog. Each 'row' in this table represents a column in the entry table. -->

<!-- Note that in bibtex (and therefore JabRef), you can create new fields on the fly. In this case, use field 'screening1' for screening the hits of this first screening iteration: simply add this field name as a 'row' (column) in the entry table. This will show, for every entry, the contents of that field (if it has any). -->

<!-- Second, you need to be able to edit the content in that field. The entry table is very convenient to maintain an overview of the entries in the database, but cannot be used for editing. To edit an entry, double click it in the entry tabel. This opens the entry editor, which has a number of tabs. Each tab shows a number of fields which can then be edited. -->

<!-- These tabs can be configured by setting the 'General fields'. Open the 'Options' drop-down menu and select 'General Fields' to configure which fields are available in the different tabs when opening an entry.  -->

<!-- ![Figure 2: Screenshot of JabRef dialog used to set the general fields.](../img/jabref--set-general-fields.png) -->

<!-- Add a dedicated field for the reviewing, showing only the title, abstract, and `screening1` fields. This allows you to focus on the relevant information while ignoring irrelevant and potentially biasing information (such as year, journal, and authors). Each row in this text area shows one tab. The first term on each row is the tab's name, followed by a colon (`:`) and then the fields shown in the tab, separated by semicolons (`;`). For example, you could add the following row: -->

<!-- `Screening Round 1:title;abstract;screening1` -->

<!-- ## Screening process -->

<!-- For every entry, add the following text in the 'screening' field: -->

<!-- - If it is excluded, add the reason, specifically (these are ordered progressively; i.e. if one of the criteria matches, apply it and move on to the next entry): -->
<!--     - **`noexperiment`** if the study does not have an experimental design; -->
<!--     - **`notargetpop`** if the study did not sample participants younger than 18 years; -->
<!--     - **`noexposure`** if the study does not compare two groups that differ in the treatment in terms of exposure; -->
<!--     - **`nophobia`** if the study did concern treatment for phobia disorders; -->
<!-- - If it is included, add **`incl`**. -->

<!-- So once JabRef is opened, when screening, make sure that the 'screening1' field is shown in the entry table (i.e. that it is one of the entry table columns), and create one entry editing tab using 'General Fields' that contains the fields `title`, `abstract`, and `screening1`. You can then use this tab for the screening. It is also convenient to show field `dupl` in either the entry table or the screening tab in the entry editor, because for duplicate records (that were identified as such - the algorithm may miss some duplicates of course), that field contains the text `dupl`. -->

<!-- Make sure to save the database with query hits under a different name than "2018-05-14-screening.bib". That is important because file "2018-05-14-screening.bib" will get overwritten if this R Markdown file is executed again. -->

<!-- ## Second query, executed at: 2018-05-23 -->

<!-- The query was updated to: -->

<!-- ``` -->
<!-- NEWQUERY -->
<!-- ``` -->

<!-- This was run at 2018-05-23 in PubMed (61 hits) and PsycINFO accessed through EbscoHost (72 hits), and exported to the RIS format (called 'medline' in PubMed). The RIS files were then imported in R using `metabefor`. -->

```{r echo=TRUE, eval=FALSE}

# ### Import PsycINFO hits
# secondQueryIteration_psycinfo <-
#   importRISlike(file.path(queryHitExportPath,
#                           "psycinfo-2018-05-23.ris"),
#                 encoding="native.enc");
# 
# ### Import PubMed hits
# secondQueryIteration_pubmed <-
#   importRISlike(file.path(queryHitExportPath,
#                           "pubmed-2018-05-23.ris"));
# 
# ### Merge the two sets of hits
# secondQueryIteration <-
#   findDuplicateReferences(primaryRefs = secondQueryIteration_psycinfo,
#                           secondaryRefs = secondQueryIteration_pubmed,
#                           duplicateFieldValue = "dupl (2nd)",
#                           newRecordValue = "PubMed (2nd)",
#                           duplicateValue = "duplicate (both PsycINFO and PubMed; 2nd)",
#                           originalValue = "PsycINFO (2nd)");
# 
# ### Generate bibtex keys
# secondQueryIteration$output$records <-
#   generateBibtexkeys(secondQueryIteration$output$records);
# 
# ### Add query date identifier to bibtex keys
# secondQueryIteration$output$records$bibtexkey <-
#   paste0(secondQueryIteration$output$records$bibtexkey,
#          "-20180523");
# 
# ### Import results from first query (these have been screened now)
# firstQueryIteration_screened <-
#   importBibtex(file.path(screeningPath,
#                          "2018-05-14-screening#1.bib"));
# 
# ### Merge the screened reference database from the first query
# ### with the database from the second query
# secondQueryIteration_merged <-
#   findDuplicateReferences(primaryRefs = firstQueryIteration_screened,
#                           secondaryRefs = secondQueryIteration,
#                           duplicateFieldValue = "Screened in first iteration",
#                           newRecordValue = "From second query",
#                           duplicateValue = "From first query (screened in first iteration)",
#                           originalValue = "screening1");
# 
# ### The new records are stored in secondQueryIteration_merged$output$newRecords, so we
# ### can copy these to the database from the first screening. We also store the entire
# ### database so that we can document the process (and if need be, check whether anything
# ### went wrong).
# 
# secondScreening <- firstQueryIteration_screened;
# 
# secondScreening$output$records <- rbind.fill(secondScreening$output$records,
#                                              secondQueryIteration_merged$output$newRecords);
# 
# ### Export the hits to bibtex for screening in JabRef
# sysrevExport(secondQueryIteration_merged,
#              filename=file.path(screeningPath,
#                                 "2018-05-23-fully-merged-database.bib"),
#              screeningType="screening");
# 
# sysrevExport(secondScreening,
#              filename=file.path(screeningPath,
#                                 "2018-05-23-screening.bib"),
#              screeningType="screening");

```

<!-- The merged bibliographic database has been stored in the screening path (`r screeningPath`), to file `2018-05-23-screening.bib`. This file can now be opened in JabRef, and should be saved to a different filename before any edits are made (because, after all, the file named `2018-05-23-screening.bib` will be overwritten every time this script runs). -->

<!-- In this merged database, field 'screening1' has been preserved. Records where this field is empty, therefore, are from the second query, and should be screened in the second screening sweep. -->

## Data extraction

### The extraction script (.rxs) {.tabset}

#### Generation of the extraction script

We will use a metabefor extraction script for the extraction of the data. The idea of this script is to extract the data from the original sources with a minimum of interpretation. The data is extracted into a machine-readable format, which then allows competely transparent further processing and synthesis.

These scripts are generated on the basis of two tables/spreadsheets. The first contains the entities to extract, such as study year, sample size, how variables were operationalised, and associations that were found. The second contains the valid values for each entity, to allow efficiently providing coders with examples, instructions, and to allow easy verification of the input.

The extraction script template is available under the second tab in this section.

```{r extraction-script-generation}

sheetsURL <- paste0("https://docs.google.com/spreadsheets/d/",
                    "1ZfPDgdeggMjCTRtqOs6muji6KRgIbb-pZ8sv_E4dCAE");

valueTemplatesSheet <- "valueTemplates";
entitiesSheet <- "entities";

fullObject <-
  rxs_fromSpecifications(gs_url = sheetsURL,
                         entitiesFilename = file.path(extractionScriptTemplatePath,
                                                      "entities-local-copy.csv"),
                         valueTemplatesFilename = file.path(extractionScriptTemplatePath,
                                                            "valueTemplates-local-copy.csv"),
                         localBackup = list(entities = file.path(extractionScriptTemplatePath,
                                                                 "entities-local-copy.csv"),
                                            valueTemplates= file.path(extractionScriptTemplatePath,
                                                                      "valueTemplates-local-copy.csv"),
                                            definitions = NULL),
                         outputFile = file.path(extractionScriptTemplatePath,
                                                "extractionScriptTemplate.rxs.Rmd"),
                         returnFullObject = TRUE);

```

#### Extraction script template

```{r extraction-script-template, results="asis"}
cat("\n\n<pre><textarea rows='40' cols=124' style='font-family:monospace;font-size:11px;white-space:pre;'>",
    unlist(fullObject$rxsTemplate),
    "</textarea></pre>\n\n",
    sep="\n");
```

### Extraction

#### Software considerations

To do the actual extraction, there are two general routes an extractor can take. The first is to use R Studio. The advantage of using R Studio is that, because each extraction script file (rxs file) is in fact an R Markdown file, it can be rendered into a report for the extracted study immediately. This can show whether any mistakes were made during extraction, and easily allows the extractor to check the results of their labour.

However, a disadvantage of R Studio is that R Markdown files are always wrapped. Wrapping means that to prevent the need for horizontal scrolling, long lines of text are displayed on multiple lines. Wrapping is almost always very useful. Text processors, for example, always wrap; text in books is always wrapped; and so is online content.

However, extraction scripts contain very long lines when closely related entities are extracted in list form; in that case, their explanation and examples are placed as comments (preceded by R's comment symbol, `#`) behind the entities and values to extract, which can look very confusing if lines are wrapped.

RStudio does use syntax coloring to clearly indicate which parts of the extraction script are comments and which parts are values, but still, extractors might find this confusing.

The second option, therefore, is to use an external editor. For extractors working in a Windows environment, Notepad++ is recommended; for extractors working in a Mac OS environment, BBEdit is recommended (extractors using a Linux distro probably already have their preferred text editors).

![`r figCap('Notepad++ when no file has been loaded yet')`](../img/notepadplusplus--empty.png)

#### Downloading the software

Working with RStudio requires installing R as well.

- R can be downloaded from [this link](https://cloud.r-project.org/) (specifically from [this link](https://cloud.r-project.org/bin/windows/base/) for Windows, from [this link](https://cloud.r-project.org/bin/macosx/) for MacOS, and through [this link](https://cloud.r-project.org/bin/linux/) for Linux).
- RStudio can be downloaded from [this link](https://www.rstudio.com/products/rstudio/download/#download).
- Notepad++ can be downloaded from [this link](https://notepad-plus-plus.org/download).
- BBEdit can be downloaded from [this link](https://www.barebones.com/products/bbedit/download.html) (the free version suffices).

#### The extraction process

When extracting articles, an extractor takes the following steps:

- Open the article (this usually means opening the relevant PDF in the `pdfs` directory).

- Copy the extraction script template to a new file in the `extraction` directory.

- Give the new file a name conform the following convention: a list of the last names of all authors, all in lower case (i.e. without capitals), separated by dashes (`-`), and ending with the year of the study, separated from the list of author names by two dashes (`--`), and ending with the extraction script extension (`.rxs.Rmd`). Thus, the filename should look something like this: `boys-marsden--2003.html`.

- Open the new (and newly renamed) extraction script in the editor of choice (see the 'Software considerations' section above).

- If you haven't looked at the extraction script yet, study it. If you encounter anything you're uncertain about, contact another team member to ask them to explain it.

- In the extraction script, scroll to the line containing the text `START: study (ROOT)`.

- Scroll downwards through the extraction script, completing each extractable entity as you encounter it. Often, the first entity will be the study identifier (usually a Digital Object Identifier or DOI).

- Once you have completed the extraction script, if you use RStudio, you can 'render' or 'knit' it by clicking the 'Knit' button at the top. This will show you what you extracted. If you made any errors (e.g. forgot a comma, or a single or double quote, or forgot to open or close a parenthesis, or mistyped a variable name, etc), this should become clear at this point. Correct any errors. (If you use another editor, you won't be able to check this at this point.)

- Repeat these steps for the next article.

If you run into any problems, clearly write them down, and depending on what you agreed with your team members, accumulate these issues and discuss them at the next meeting, or immediately pass them on using whichever medium you use.

